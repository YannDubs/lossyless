# @package _global_
job_id: ${hydra:job.num}_${hydra:job.id} # job num is number in sweep. Id is unique ID like SLURM_JOB_ID


hydra:
  launcher:
    # maximum time for the job in minutes
    timeout_min: ${timeout}
    # number of cpus to use for each task
    cpus_per_task: 10
    # number of gpus to use on each node
    gpus_per_node: ${trainer.gpus}
    # number of tasks to spawn on each node
    tasks_per_node: 1 # number of tasks on single machine
    # memory to reserve for the job on each node (in GB)
    mem_gb: 32
    # number of nodes to use for the job
    nodes: ${trainer.num_nodes}
    # name of the job
    name: ${name}


    # slurm partition to use on the cluster
    partition: gpu # wsgpu,interactive,cpu,nlp
    comment: null 
    constraint: null 
    exclude: null
    array_parallelism: 30
    
    max_num_timeout: 30 # alow resume from checkpointing
    additional_parameters:
      qos: normal # nlp

  run:
    # unfortunately cannot use hydra: is hydra so need to do everything by hand
    # i.e. cannot use ${paths.work}/${job_id}
    dir: /scratch/gobi2/${user}/checkpoints/${now:%Y-%m-%d_%H-%M-%S}
    #/checkpoint/${user}/${hydra.job.id}/${now:%Y-%m-%d_%H-%M-%S}

  sweep:
    dir: /scratch/gobi2/${user}/checkpoints/${now:%Y-%m-%d_%H-%M-%S}
    #/checkpoint/${user}/${hydra.job.id}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}_${hydra.job.id}