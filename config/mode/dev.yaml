# @package _global_

# check that everything is running correctly (2 epochs small data)

timeout: 60

other:
  is_quick: True

trainer:
  max_epochs: 5
  log_every_n_steps: 10
  num_sanity_val_steps: 0 # was giving error
  # uses 5 % of data
  limit_val_batches: 0.2
  limit_train_batches: 0.05
  limit_test_batches: 0.05

data_feat:
  kwargs:
    # use smaller because was giving error
    batch_size: 128
    val_batch_size: 128

data_pred:
  kwargs:
    # use smaller because was giving error
    batch_size: 128
    val_batch_size: 128

logger:
  wandb_kwargs: 
    tags: [dev, quick]
    anonymous: true
    project: tmp

callbacks:
  GPUStatsMonitor: 
    is_use : False