# @package _global_
defaults:
  - base@distortion

distortion:
  mode: contrastive
  kwargs:
    temperature: 0.1 # decreasing temperature seems to help distortion but worst accuracy !
    is_symmetric: true
    effective_batch_size: ${data.length} # new but seems to work better use `null` if want to deactivate
    is_project: true # strongly recommended
    is_cosine: true # recommended
    project_kwargs:
      mode: mlp
      out_shape: 128

data_feat:
  kwargs:
    batch_size: 256 # better results with large batch sizes for estimating MI (like 1024 but then you need LARS)
    dataset_kwargs:
      additional_target: equiv_x

optimizer_feat:
  kwargs:
    is_lars: false # true is usefull if have to use large batch sizes (but currently bug)

optimizer_coder:
  kwargs:
    is_lars: ${optimizer_feat.kwargs.is_lars} # will usually use same batch size => also LARS for pred

optimizer_online:
  kwargs:
    is_lars: ${optimizer_feat.kwargs.is_lars} # will usually use same batch size => also LARS for pred