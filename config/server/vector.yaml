# @package _global_
job_id: ${hydra:job.num}_${hydra:job.id} # job num is number in sweep. Id is unique ID like SLURM_JOB_ID


hydra:
  launcher:
    # maximum time for the job in minutes
    timeout_min: ${timeout}
    # number of cpus to use for each task
    cpus_per_task: 10
    # number of gpus to use on each node
    gpus_per_node: ${trainer.gpus}
    # number of tasks to spawn on each node
    tasks_per_node: 1 # number of tasks on single machine
    # memory to reserve for the job on each node (in GB)
    mem_gb: 32
    # number of nodes to use for the job
    nodes: ${trainer.num_nodes}
    # name of the job
    name: ${experiment}

    # slurm partition to use on the cluster
    partition: rtx6000 # cpu,interactive,t4v1,t4v2,p100,rtx6000
    comment: null 
    constraint: null 
    exclude: null
    array_parallelism: 30
    
    max_num_timeout: 30 # alow resume from checkpointing
    additional_parameters:
      qos: normal # normal, high, deadline, nopreemption (this is the stream of execution )

  run:
    # unfortunately cannot use hydra: is hydra so need to do everything by hand
    # i.e. cannot use ${paths.work}/${job_id}
    dir: /checkpoint/${user}/${now:%Y-%m-%d_%H-%M-%S}
    #/checkpoint/${user}/${hydra.job.id}/${now:%Y-%m-%d_%H-%M-%S}

  sweep:
    dir: /checkpoint/${user}/${now:%Y-%m-%d_%H-%M-%S}
    #/checkpoint/${user}/${hydra.job.id}/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num}_${hydra.job.id}

# NOTE:
# I also had to change the command in submitit. specificall in submitit/slurm/slurm 
# function: _make_sbatch_string replace the end with
# lines += [
#       "",
#       "# command",
#       "export SUBMITIT_EXECUTOR=slurm",
#       "export MKL_SERVICE_FORCE_INTEL=1",
#       f"srun --mem {mem} --output '{stdout}' --error '{stderr}' --unbuffered {command}",
#   ]