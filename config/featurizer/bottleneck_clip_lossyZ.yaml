# @package _global_
defaults:
  - neural_feat@featurizer
  - override /architecture@encoder: clip
  - override /distortion: lossyZ
  - override /rate: H_hyper
  - override /finetune: freezer
  - override /scheduler@scheduler_feat: expdecay1000
  - override /scheduler@scheduler_coder: expdecay1000

data_feat:
  kwargs:
    batch_size: 64
    dataset_kwargs:
      base_resize: clip
      equivalence: ["resize","crop"]

data_pred:
  kwargs:
    dataset_kwargs:
      base_resize: clip
      equivalence: ["resize","crop"]

featurizer:
  name: bottleneck_clip_lossyZ
  loss:
    beta_anneal: linear
    beta: 1e-2
    factor_beta: 1e-2

encoder:
  z_dim: 512

rate:
  kwargs: 
    is_endToEnd: False # shouldn't be needed becasue already frozen encoder

optimizer_feat:
  mode: AdamW
  kwargs:
    lr: 5e-5
    weight_decay: 3e-8

optimizer_coder:
  mode: AdamW
  kwargs:
    lr: 3e-4
    weight_decay: 1e-6








