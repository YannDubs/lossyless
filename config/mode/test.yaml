# @package _global_
# test whether can overfit training
name: test_${now:%Y-%m-%d_%H-%M-%S}

trainer:
  track_grad_norm: 2 # use 2 to track L2 norms of grad
  overfit_batches: 0.01 # use 0.01 to make sure you can overfit 1% of training data => training works
  weights_summary: top # full to print show the entire model 
  max_epochs: 5

logger:
  wandb:
    tags: test
    anonymous: true

callbacks:
  additional: ["GPUStatsMonitor","TrainingDataMonitor","ModuleDataMonitor"] # if add other callbacks through additional will be replaced

  TrainingDataMonitor:
    log_every_n_steps: 100

  ModuleDataMonitor:
    log_every_n_steps: 100
    submodules: ["p_ZlX.mapper"]
  