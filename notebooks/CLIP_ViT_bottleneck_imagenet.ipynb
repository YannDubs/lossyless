{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nearby-grenada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/lossyless\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "strange-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pl_bolts/utils/warnings.py:30: UserWarning: You want to use `gym` which is not installed yet, install it with `pip install gym`.\n",
      "  stdout_func(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from io import BytesIO, StringIO\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from featurize import (\n",
    "    CIFAR10,\n",
    "    CIFAR100,\n",
    "    STL10Dataset,\n",
    "    ImagenetDataset,\n",
    "    ImagenetteDataset,\n",
    "    get_featurized_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strategic-flight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done featurizing ImagenetDataset\n",
      "Done featurizing CIFAR100\n",
      "Done featurizing STL10\n"
     ]
    }
   ],
   "source": [
    "model = \"CLIP_ViT\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "Datasets = dict(\n",
    "    ImagenetDataset=ImagenetDataset, Cifar10, CIFAR100=CIFAR100,STL10=STL10Dataset)\n",
    "features = get_featurized_data(Datasets, model, device=device, is_half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "missing-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "CLF = partial(\n",
    "    SGDClassifier,\n",
    "    random_state=123,\n",
    "    n_jobs=-1,\n",
    "    loss=\"log\",\n",
    "    penalty=\"l2\",\n",
    "    alpha=0.0001,\n",
    "    max_iter=100,\n",
    "    learning_rate=\"adaptive\",\n",
    "    eta0=0.1,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "KNN1 = partial(\n",
    "    KNeighborsClassifier,\n",
    "    n_neighbors=1,\n",
    "    algorithm=\"kd_tree\",\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electronic-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(data):\n",
    "    Z_train = features[data][\"train\"][\"Z\"][:]\n",
    "    Y_train = features[data][\"train\"][\"Y\"][:]\n",
    "    Z_test = features[data][\"test\"][\"Z\"][:]\n",
    "    Y_test = features[data][\"test\"][\"Y\"][:]\n",
    "    return Z_train, Y_train, Z_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "union-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lossless_size(Z_test):\n",
    "    Z_test = Z_test.astype(np.float16)\n",
    "    tmp = BytesIO()\n",
    "    np.savez_compressed(tmp, Z=Z_test)\n",
    "    out = tmp.getbuffer().nbytes * 8 / 1e6\n",
    "    tmp.close()\n",
    "    print(f\"{out:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identical-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_YlM(Z_test, Y_test):\n",
    "    knn1 = KNN1()\n",
    "    knn1.fit(Z_test, Y_test)\n",
    "    accuracy = knn1.score(Z_test, Y_test)\n",
    "    print(f\"Test information {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_hat(compressor, datamodule):\n",
    "    out = trainer.predict(\n",
    "        compressor,\n",
    "        dataloaders=[datamodule.train_dataloader(), datamodule.test_dataloader()],\n",
    "    )\n",
    "    Z_train_hat = np.concatenate([o[0] for o in out[0]], axis=0)\n",
    "    Y_train_hat = np.concatenate([o[1] for o in out[0]], axis=0)\n",
    "    Z_test_hat = np.concatenate([o[0] for o in out[1]], axis=0)\n",
    "    Y_test_hat = np.concatenate([o[1] for o in out[1]], axis=0)\n",
    "    return Z_train_hat, Y_train_hat, Z_test_hat, Y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wrapped-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.datamodules import SklearnDataModule\n",
    "\n",
    "def get_datamodule(Z_train, Y_train, Z_test, Y_test):\n",
    "    datamodule = SklearnDataModule(\n",
    "        Z_train,\n",
    "        Y_train,\n",
    "        x_test=Z_test,\n",
    "        y_test=Y_test,\n",
    "        num_workers=16,\n",
    "        batch_size=64,\n",
    "        val_split=0,\n",
    "    )\n",
    "\n",
    "    datamodule.val_dataloader = datamodule.test_dataloader\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "seventh-holder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.86 s, sys: 384 ms, total: 6.25 s\n",
      "Wall time: 6.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = \"ImagenetDataset\"\n",
    "\n",
    "Z_train, Y_train, Z_test, Y_test = get_train_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-storage",
   "metadata": {},
   "source": [
    "# Lossless Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "revised-panama",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9G\tdata/imagenet256/val\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/imagenet256/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "operating-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet 256 \n",
    "#print(f\"{2.9 * 1e9 * 8 / 1e6:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "referenced-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69600.0 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "# real imagenet (not on this computer)\n",
    "print(f\"{8.7 * 1e9 * 8 / 1e6:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information can safely be assumed to be 100% because you never have 2 same images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-invasion",
   "metadata": {},
   "source": [
    "# Lossless Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "african-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72658\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train, Y_train)\n",
    "accuracy = clf_lossless.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "elder-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379.6 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "# hdf5\n",
    "out = features[data][\"test\"][\"Z\"].id.get_storage_size() * 8 / 1e6\n",
    "print(f\"{out:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "mediterranean-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379.6 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "# savez\n",
    "get_lossless_size(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "killing-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-dover",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proud-shanghai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = make_pipeline(PCA(n_components=220), CLF())\n",
    "clf.fit(Z_train, Y_train)\n",
    "accuracy = clf.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "laughing-assault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163.8 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "pca = clf.named_steps[\"pca\"]\n",
    "Z_test_pca = pca.transform(Z_test)\n",
    "get_lossless_size(Z_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-wellington",
   "metadata": {},
   "source": [
    "# Learned Lossy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pytorch_lightning as pl\n",
    "from lossyless import get_rate_estimator\n",
    "\n",
    "import torch\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from lossyless.helpers import OrderedSet, append_optimizer_scheduler_\n",
    "from utils.helpers import dict2namespace\n",
    "\n",
    "\n",
    "class ArrayCompressor(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        **hparams,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hparams = dict2namespace(hparams)\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.rate_estimator = get_rate_estimator(\n",
    "            self.hparams.mode, z_dim=self.hparams.input_dim, **self.hparams.kwargs\n",
    "        )\n",
    "        self.alpha = torch.nn.Parameter(torch.ones(self.hparams.input_dim))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        z, y = batch\n",
    "        z = (z * self.alpha.exp()).unsqueeze(0)\n",
    "        z_hat, *_ = self.rate_estimator(z, None, self)\n",
    "        z_hat = z_hat.squeeze(0) / self.alpha.exp()\n",
    "        return z_hat, y\n",
    "\n",
    "    def get_specific_parameters(self, mode):\n",
    "        \"\"\"Returns an iterator over the desired model parameters.\"\"\"\n",
    "        all_param = OrderedSet(self.parameters())\n",
    "        coder_param = OrderedSet(self.rate_estimator.aux_parameters())\n",
    "        if mode == \"main\":\n",
    "            return all_param - coder_param\n",
    "        elif mode == \"coder\":\n",
    "            return coder_param\n",
    "        else:\n",
    "            raise ValueError(f\"Unkown parameter mode={mode}.\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers, schedulers = [], []\n",
    "\n",
    "        append_optimizer_scheduler_(\n",
    "            self.hparams.optimizer_feat,\n",
    "            self.hparams.scheduler_feat,\n",
    "            self.get_specific_parameters(\"main\"),\n",
    "            optimizers,\n",
    "            schedulers,\n",
    "        )\n",
    "\n",
    "        append_optimizer_scheduler_(\n",
    "            self.hparams.optimizer_coder,\n",
    "            self.hparams.scheduler_coder,\n",
    "            self.get_specific_parameters(\"coder\"),\n",
    "            optimizers,\n",
    "            schedulers,\n",
    "        )\n",
    "\n",
    "\n",
    "        return optimizers, schedulers\n",
    "\n",
    "    def step(self, batch):\n",
    "        z, _ = batch\n",
    "\n",
    "        z_in = (z * self.alpha.exp()).unsqueeze(0)\n",
    "        z_hat, rates, logs, r_other = self.rate_estimator(z_in, None, self)\n",
    "        z_hat = z_hat.squeeze(0) / self.alpha.exp()\n",
    "\n",
    "        rate = rates.mean()\n",
    "        distortion = torch.norm(z - z_hat, p=self.hparams.p_norm, dim=-1).mean()\n",
    "        loss = distortion + self.hparams.beta * rate\n",
    "\n",
    "        logs[\"rate\"] = rate / math.log(2)\n",
    "        logs[\"distortion\"] = distortion / math.log(2)\n",
    "        logs[\"loss\"] = loss\n",
    "\n",
    "        self.log(\"rate\", rate / math.log(2), prog_bar=True)\n",
    "        self.log(\"distortion\", distortion / math.log(2), prog_bar=True)\n",
    "\n",
    "        return loss, logs\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx=0):\n",
    "        if optimizer_idx == 0:\n",
    "            loss, logs = self.step(batch)\n",
    "            self.log_dict({f\"train/pred/{k}\": v for k, v in logs.items()})\n",
    "        else:\n",
    "            loss = self.rate_estimator.aux_loss()\n",
    "            self.log(f\"train/pred/coder_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch)\n",
    "        self.log_dict({f\"val/pred/{k}\": v for k, v in logs.items()})\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, logs = self.step(batch)\n",
    "        self.log_dict({f\"test/pred/{k}\": v for k, v in logs.items()})\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "outer-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "\n",
    "compressor = ArrayCompressor(\n",
    "    input_dim=512,\n",
    "    beta=1e-2,\n",
    "    p_norm=1,\n",
    "    mode=\"H_hyper\",\n",
    "    kwargs={},\n",
    "    optimizer_coder=dict(mode=\"Adam\", kwargs=dict(lr=1e-3)),\n",
    "    optimizer_feat=dict(mode=\"Adam\", kwargs=dict(lr=1e-2)),\n",
    "    scheduler_feat=dict(modes=[\"expdecay\"], kwargs=dict(expdecay=dict(epochs=max_epochs, decay_factor=100))),\n",
    "    scheduler_coder=dict(modes=[\"expdecay\"], kwargs=dict(expdecay=dict(epochs=max_epochs, decay_factor=100))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twelve-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, precision=32, max_epochs=max_epochs, limit_val_batches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-dietary",
   "metadata": {},
   "source": [
    "## Same Data\n",
    "The first question we will ask ourselves is whether these features can be used for good compression when the entropy model is trained on the same data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unlimited-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ImagenetDataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "equal-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(Z_train, Y_train, Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "respected-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = False\n",
    "if is_train:\n",
    "    trainer.fit(compressor, datamodule=datamodule)\n",
    "    trainer.save_checkpoint(\"compressor.ckpt\")\n",
    "else:\n",
    "    compressor = ArrayCompressor.load_from_checkpoint(checkpoint_path=\"compressor.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "practical-contact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38754b27c06f415993e06621469c2e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'distortion': 7.373038291931152,\n",
      " 'rate': 2529.230712890625,\n",
      " 'test/pred/H_ZlX': 0.0,\n",
      " 'test/pred/H_q_S': 0.0,\n",
      " 'test/pred/H_q_Z': 2529.230712890625,\n",
      " 'test/pred/H_q_ZlS': 2529.230712890625,\n",
      " 'test/pred/distortion': 7.373038291931152,\n",
      " 'test/pred/loss': 22.641889572143555,\n",
      " 'test/pred/rate': 2529.230712890625}\n",
      "--------------------------------------------------------------------------------\n",
      "126.5 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "out = trainer.test(model=compressor, test_dataloaders=[datamodule.test_dataloader()])\n",
    "n_test = len(Z_test)\n",
    "n_per_test = out[0][\"test/pred/rate\"]\n",
    "print(f\"{ n_test* n_per_test / 1e6 :.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ambient-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jackpot is 1380.0 bit rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "equipped-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Your predict_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b94589e3538402396b21ab9ef9bef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_train_hat, Y_train_hat, Z_test_hat, Y_test_hat = get_train_test_hat(compressor, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prepared-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72622\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train, Y_train)\n",
    "accuracy = clf_lossless.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "likely-sacrifice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test_hat, Y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-resolution",
   "metadata": {},
   "source": [
    "## Different Data\n",
    "At the end of the day what we want is to have a pretrained compressor that can be used for any downstream data. So no only do you want generalization of the entropy model and representation learning to test data but also to different domains. It's not obvious whether this is possible.We know empricially that CLIP will be able to generalizat well, but that might not be the case for the entropy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "obvious-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done featurizing CIFAR100\n",
      "Done featurizing CIFAR10\n",
      "Done featurizing ImagenetDataset\n",
      "Done featurizing STL10\n"
     ]
    }
   ],
   "source": [
    "Datasets = dict(\n",
    "    CIFAR100=CIFAR100, CIFAR10=CIFAR10, ImagenetDataset=ImagenetDataset, STL10=STL10Dataset)\n",
    "features = get_featurized_data(Datasets, model, device=device, is_half=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-cowboy",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "gothic-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"CIFAR10\"\n",
    "Z_train, Y_train, Z_test, Y_test = get_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "intended-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30M\tdata/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/cifar-10-batches-py/test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "convenient-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.0 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "print(f\"{30 * 1e6 * 8 / 1e6:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "biological-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.8 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "get_lossless_size(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "brutal-render",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9498\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train, Y_train)\n",
    "accuracy = clf_lossless.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "massive-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "approximate-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(Z_train, Y_train, Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "animated-wesley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa3043c95b84c3b9935c7abfae408c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'distortion': 7.375333786010742,\n",
      " 'rate': 2558.691162109375,\n",
      " 'test/pred/H_ZlX': 0.0,\n",
      " 'test/pred/H_q_S': 0.0,\n",
      " 'test/pred/H_q_Z': 2558.691162109375,\n",
      " 'test/pred/H_q_ZlS': 2558.691162109375,\n",
      " 'test/pred/distortion': 7.375333786010742,\n",
      " 'test/pred/loss': 22.847688674926758,\n",
      " 'test/pred/rate': 2558.691162109375}\n",
      "--------------------------------------------------------------------------------\n",
      "25.6 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "out = trainer.test(model=compressor, test_dataloaders=[datamodule.test_dataloader()])\n",
    "n_test = len(Z_test)\n",
    "n_per_test = out[0][\"test/pred/rate\"]\n",
    "print(f\"{ n_test* n_per_test / 1e6 :.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-relations",
   "metadata": {},
   "source": [
    "You see that the performance is not too bad (considering that for a compressor trained from that datadistribution you were getting 15.3 Mega Bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "existing-seven",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Your predict_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad322839334448a1beda3b46f3259868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_train_hat, Y_train_hat, Z_test_hat, Y_test_hat = get_train_test_hat(compressor, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cordless-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9489\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train_hat, Y_train_hat)\n",
    "accuracy = clf_lossless.score(Z_test_hat, Y_test_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "quick-local",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test_hat, Y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-coral",
   "metadata": {},
   "source": [
    "### CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stable-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"CIFAR100\"\n",
    "Z_train, Y_train, Z_test, Y_test = get_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "activated-garbage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30M\tdata/cifar-100-python/test\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/cifar-100-python/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ceramic-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.0 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "print(f\"{30 * 1e6 * 8 / 1e6:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "opposite-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.9 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "get_lossless_size(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "virgin-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7969\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train, Y_train)\n",
    "accuracy = clf_lossless.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "portable-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "tight-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(Z_train, Y_train, Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "brutal-warner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95902b59e6d94fd9ae9ede6e72585dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'distortion': 7.372977256774902,\n",
      " 'rate': 2551.51513671875,\n",
      " 'test/pred/H_ZlX': 0.0,\n",
      " 'test/pred/H_q_S': 0.0,\n",
      " 'test/pred/H_q_Z': 2551.51513671875,\n",
      " 'test/pred/H_q_ZlS': 2551.51513671875,\n",
      " 'test/pred/distortion': 7.372977256774902,\n",
      " 'test/pred/loss': 22.796316146850586,\n",
      " 'test/pred/rate': 2551.51513671875}\n",
      "--------------------------------------------------------------------------------\n",
      "25.5 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "out = trainer.test(model=compressor, test_dataloaders=[datamodule.test_dataloader()])\n",
    "n_test = len(Z_test)\n",
    "n_per_test = out[0][\"test/pred/rate\"]\n",
    "print(f\"{ n_test* n_per_test / 1e6 :.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "systematic-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Your predict_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b460d13e36459d8b9a835e7a944b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_train_hat, Y_train_hat, Z_test_hat, Y_test_hat = get_train_test_hat(compressor, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "acquired-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7966\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train_hat, Y_train_hat)\n",
    "accuracy = clf_lossless.score(Z_test_hat, Y_test_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "possible-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test_hat, Y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-affect",
   "metadata": {},
   "source": [
    "### STL10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "favorite-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"STL10\"\n",
    "Z_train, Y_train, Z_test, Y_test = get_train_test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "welcome-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211M\tdata/stl10_binary/test_X.bin\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/stl10_binary/test_X.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "remarkable-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688.0 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "print(f\"{211 * 1e6 * 8 / 1e6:.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "demonstrated-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.7 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "get_lossless_size(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "union-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985875\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train, Y_train)\n",
    "accuracy = clf_lossless.score(Z_test, Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eleven-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "linear-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = get_datamodule(Z_train, Y_train, Z_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eleven-major",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875028c5df1741fabab0cea5685fbcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'distortion': 7.375964164733887,\n",
      " 'rate': 2542.785400390625,\n",
      " 'test/pred/H_ZlX': 0.0,\n",
      " 'test/pred/H_q_S': 0.0,\n",
      " 'test/pred/H_q_Z': 2542.785400390625,\n",
      " 'test/pred/H_q_ZlS': 2542.785400390625,\n",
      " 'test/pred/distortion': 7.375964164733887,\n",
      " 'test/pred/loss': 22.73787498474121,\n",
      " 'test/pred/rate': 2542.785400390625}\n",
      "--------------------------------------------------------------------------------\n",
      "20.3 Mega Bits\n"
     ]
    }
   ],
   "source": [
    "out = trainer.test(model=compressor, test_dataloaders=[datamodule.test_dataloader()])\n",
    "n_test = len(Z_test)\n",
    "n_per_test = out[0][\"test/pred/rate\"]\n",
    "print(f\"{ n_test* n_per_test / 1e6 :.1f} Mega Bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adopted-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/utilities/distributed.py:51: UserWarning: Your predict_dataloader has `shuffle=True`, it is best practice to turn this off for validation and test dataloaders.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168ad690ed5049ab8b199d542f3bc19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_train_hat, Y_train_hat, Z_test_hat, Y_test_hat = get_train_test_hat(compressor, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "solid-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986\n"
     ]
    }
   ],
   "source": [
    "clf_lossless = CLF()\n",
    "clf_lossless.fit(Z_train_hat, Y_train_hat)\n",
    "accuracy = clf_lossless.score(Z_test_hat, Y_test_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cellular-delhi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test information 100.0%\n"
     ]
    }
   ],
   "source": [
    "H_YlM(Z_test_hat, Y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-insight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
